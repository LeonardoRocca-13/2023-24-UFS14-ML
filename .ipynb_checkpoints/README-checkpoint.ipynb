{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51bd737f",
   "metadata": {},
   "source": [
    "Build our Docker image \"my-custom-sagemaker-image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "172507ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "image_uris.retrieve(framework='tensorflow',region='us-east-1',version='2.12.0',image_scope='training',instance_type='ml.c5.4xlarge', py_version='py310')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1e4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [sagemaker-training internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 633B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [sagemaker-training internal] load .dockerignore\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [sagemaker-training auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [sagemaker-training internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py3\n",
      "#4 DONE 0.3s\n",
      "\n",
      "#5 [sagemaker-training internal] load build context\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [sagemaker-training 1/3] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py3@sha256:2bb61fb08ad07b5993715f125e2cb7b0434ba665fdc9c540a471efede65e14b9\n",
      "#6 resolve 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py3@sha256:2bb61fb08ad07b5993715f125e2cb7b0434ba665fdc9c540a471efede65e14b9 0.0s done\n",
      "#6 ...\n",
      "\n",
      "#5 [sagemaker-training internal] load build context\n",
      "#5 transferring context: 715B done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [sagemaker-training 1/3] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py3@sha256:2bb61fb08ad07b5993715f125e2cb7b0434ba665fdc9c540a471efede65e14b9\n",
      "#6 sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 0B / 45.96MB 0.1s\n",
      "#6 sha256:5dfa26c6b9c9d1ccbcb1eaa65befa376805d9324174ac580ca76fdedc3575f54 0B / 852B 0.1s\n",
      "#6 sha256:0ba7bf18aa406cb7dc372ac732de222b04d1c824ff1705d8900831c3d1361ff5 0B / 527B 0.1s\n",
      "#6 sha256:2bb61fb08ad07b5993715f125e2cb7b0434ba665fdc9c540a471efede65e14b9 3.46kB / 3.46kB done\n",
      "#6 sha256:e77085e0f8445478354c1b396cabb08311081f106764ee1d19ae52a5ab876ecb 12.29kB / 12.29kB done\n",
      "#6 sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 10.49MB / 45.96MB 0.2s\n",
      "#6 sha256:5dfa26c6b9c9d1ccbcb1eaa65befa376805d9324174ac580ca76fdedc3575f54 852B / 852B 0.1s done\n",
      "#6 sha256:0ba7bf18aa406cb7dc372ac732de222b04d1c824ff1705d8900831c3d1361ff5 527B / 527B 0.1s done\n",
      "#6 sha256:4c6ec688ebe374ea7d89ce967576d221a177ebd2c02ca9f053197f954102e30b 0B / 169B 0.2s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 0B / 223.49MB 0.2s\n",
      "#6 sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 24.12MB / 45.96MB 0.4s\n",
      "#6 sha256:4c6ec688ebe374ea7d89ce967576d221a177ebd2c02ca9f053197f954102e30b 169B / 169B 0.3s done\n",
      "#6 sha256:e547b65ac33b103c12bfc6478190eefb29e33b75ebfac261a7ff4c959ac49b21 0B / 4.20MB 0.4s\n",
      "#6 sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 28.31MB / 45.96MB 0.5s\n",
      "#6 sha256:e547b65ac33b103c12bfc6478190eefb29e33b75ebfac261a7ff4c959ac49b21 2.10MB / 4.20MB 0.5s\n",
      "#6 sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 33.55MB / 45.96MB 0.6s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 14.68MB / 223.49MB 0.6s\n",
      "#6 sha256:e547b65ac33b103c12bfc6478190eefb29e33b75ebfac261a7ff4c959ac49b21 4.20MB / 4.20MB 0.6s done\n",
      "#6 sha256:3f6e3c32bbdfc30253b6b509fa08eb464a2711ea3cf32c377d7692803b18d6c0 0B / 488B 0.6s\n",
      "#6 sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 44.04MB / 45.96MB 0.8s\n",
      "#6 sha256:3f6e3c32bbdfc30253b6b509fa08eb464a2711ea3cf32c377d7692803b18d6c0 488B / 488B 0.7s done\n",
      "#6 sha256:61930c785627a05f2a9b6ce17846e98791509878c0ac1e1bb4693eade762a08e 434B / 434B 0.8s done\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 0B / 840.00MB 0.8s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 31.46MB / 223.49MB 0.9s\n",
      "#6 sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 45.96MB / 45.96MB 1.0s done\n",
      "#6 extracting sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 0.1s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 0B / 213.59MB 1.1s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 47.19MB / 223.49MB 1.3s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 58.72MB / 223.49MB 1.6s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 13.63MB / 213.59MB 1.6s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 49.28MB / 840.00MB 1.9s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 73.40MB / 223.49MB 2.0s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 25.17MB / 213.59MB 2.0s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 84.93MB / 223.49MB 2.3s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 40.89MB / 213.59MB 2.5s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 96.47MB / 223.49MB 2.6s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 110.10MB / 223.49MB 3.0s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 57.67MB / 213.59MB 3.0s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 94.37MB / 840.00MB 3.1s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 69.21MB / 213.59MB 3.3s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 123.73MB / 223.49MB 3.4s\n",
      "#6 extracting sha256:4007a89234b4f56c03e6831dc220550d2e5fba935d9f5f5bcea64857ac4f4888 2.6s done\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 137.36MB / 223.49MB 3.8s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 87.03MB / 213.59MB 3.8s\n",
      "#6 extracting sha256:5dfa26c6b9c9d1ccbcb1eaa65befa376805d9324174ac580ca76fdedc3575f54\n",
      "#6 extracting sha256:5dfa26c6b9c9d1ccbcb1eaa65befa376805d9324174ac580ca76fdedc3575f54 done\n",
      "#6 extracting sha256:0ba7bf18aa406cb7dc372ac732de222b04d1c824ff1705d8900831c3d1361ff5\n",
      "#6 extracting sha256:0ba7bf18aa406cb7dc372ac732de222b04d1c824ff1705d8900831c3d1361ff5 done\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 150.99MB / 223.49MB 4.2s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 101.71MB / 213.59MB 4.2s\n",
      "#6 extracting sha256:4c6ec688ebe374ea7d89ce967576d221a177ebd2c02ca9f053197f954102e30b done\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 138.41MB / 840.00MB 4.3s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 168.82MB / 223.49MB 4.7s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 118.49MB / 213.59MB 4.7s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 183.50MB / 223.49MB 5.1s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 133.17MB / 213.59MB 5.1s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 197.13MB / 223.49MB 5.5s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 181.40MB / 840.00MB 5.5s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 147.85MB / 213.59MB 5.5s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 159.38MB / 213.59MB 5.8s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 211.81MB / 223.49MB 5.9s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 173.02MB / 213.59MB 6.2s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 223.49MB / 223.49MB 6.4s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 189.79MB / 213.59MB 6.5s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 225.44MB / 840.00MB 6.6s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 206.57MB / 213.59MB 6.8s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 271.58MB / 840.00MB 7.2s\n",
      "#6 sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 223.49MB / 223.49MB 7.6s done\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 325.06MB / 840.00MB 7.7s\n",
      "#6 extracting sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 375.39MB / 840.00MB 8.2s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 427.82MB / 840.00MB 8.7s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 479.20MB / 840.00MB 9.2s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 522.19MB / 840.00MB 9.6s\n",
      "#6 sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 213.59MB / 213.59MB 9.9s done\n",
      "#6 sha256:00637bfc9c8fc84c16c291fce3fe185c53a72f3b14d3b7436297a0a21f11a4a7 0B / 1.86kB 10.0s\n",
      "#6 sha256:f8fca23a08d5ce506d7fc746e0e57f16d39bff2d5cc0ea402e09253ee25976c0 0B / 433B 10.0s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 573.57MB / 840.00MB 10.1s\n",
      "#6 sha256:00637bfc9c8fc84c16c291fce3fe185c53a72f3b14d3b7436297a0a21f11a4a7 1.86kB / 1.86kB 10.0s done\n",
      "#6 sha256:f8fca23a08d5ce506d7fc746e0e57f16d39bff2d5cc0ea402e09253ee25976c0 433B / 433B 10.1s done\n",
      "#6 sha256:6283945826970ad43bcd9f0b50b1080fbbb913d5926a1a9410638c62f462d3e5 0B / 1.86kB 10.1s\n",
      "#6 sha256:6283945826970ad43bcd9f0b50b1080fbbb913d5926a1a9410638c62f462d3e5 1.86kB / 1.86kB 10.2s done\n",
      "#6 sha256:f97f975e4a1db12b9ab3d8302a5b08b38176a03ea9c746831e2b50e5d1e73a39 1.44kB / 1.44kB 10.2s done\n",
      "#6 sha256:3cc12e483cba866e22a0c454406874da654b66d500f3321ec2acb4c6801ca1e9 0B / 5.96MB 10.3s\n",
      "#6 sha256:3cc12e483cba866e22a0c454406874da654b66d500f3321ec2acb4c6801ca1e9 4.19MB / 5.96MB 10.4s\n",
      "#6 sha256:3cc12e483cba866e22a0c454406874da654b66d500f3321ec2acb4c6801ca1e9 5.96MB / 5.96MB 10.5s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 617.61MB / 840.00MB 10.6s\n",
      "#6 sha256:3cc12e483cba866e22a0c454406874da654b66d500f3321ec2acb4c6801ca1e9 5.96MB / 5.96MB 10.7s done\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 670.04MB / 840.00MB 11.1s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 720.44MB / 840.00MB 11.6s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 770.70MB / 840.00MB 12.1s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 823.13MB / 840.00MB 12.6s\n",
      "#6 extracting sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 5.1s\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 840.00MB / 840.00MB 17.8s\n",
      "#6 extracting sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 10.3s\n",
      "#6 extracting sha256:d9203868dc4c40f091a2cc6f74049054018a68bdd8c499cf5a9ed663fd24f596 10.6s done\n",
      "#6 extracting sha256:e547b65ac33b103c12bfc6478190eefb29e33b75ebfac261a7ff4c959ac49b21\n",
      "#6 sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 840.00MB / 840.00MB 21.1s done\n",
      "#6 extracting sha256:e547b65ac33b103c12bfc6478190eefb29e33b75ebfac261a7ff4c959ac49b21 0.2s done\n",
      "#6 extracting sha256:3f6e3c32bbdfc30253b6b509fa08eb464a2711ea3cf32c377d7692803b18d6c0\n",
      "#6 extracting sha256:3f6e3c32bbdfc30253b6b509fa08eb464a2711ea3cf32c377d7692803b18d6c0 done\n",
      "#6 extracting sha256:61930c785627a05f2a9b6ce17846e98791509878c0ac1e1bb4693eade762a08e done\n",
      "#6 extracting sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 0.1s\n",
      "#6 extracting sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 5.1s\n",
      "#6 extracting sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 10.2s\n",
      "#6 extracting sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 15.3s\n",
      "#6 extracting sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 20.4s\n",
      "#6 extracting sha256:aa3096b27f28bcd0ebba49b3c1222c13253a3fa6c556103e8d7995a83eb1df58 24.5s done\n",
      "#6 extracting sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 0.1s\n",
      "#6 extracting sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 5.2s\n",
      "#6 extracting sha256:d972672eaf57af14b5c61e41f473424566c0eaf2d28c4bd5624d004d6023c64a 7.5s done\n",
      "#6 extracting sha256:f8fca23a08d5ce506d7fc746e0e57f16d39bff2d5cc0ea402e09253ee25976c0 done\n",
      "#6 extracting sha256:00637bfc9c8fc84c16c291fce3fe185c53a72f3b14d3b7436297a0a21f11a4a7 done\n",
      "#6 extracting sha256:6283945826970ad43bcd9f0b50b1080fbbb913d5926a1a9410638c62f462d3e5\n",
      "#6 extracting sha256:6283945826970ad43bcd9f0b50b1080fbbb913d5926a1a9410638c62f462d3e5 done\n",
      "#6 extracting sha256:f97f975e4a1db12b9ab3d8302a5b08b38176a03ea9c746831e2b50e5d1e73a39 done\n",
      "#6 extracting sha256:3cc12e483cba866e22a0c454406874da654b66d500f3321ec2acb4c6801ca1e9 0.1s\n",
      "#6 extracting sha256:3cc12e483cba866e22a0c454406874da654b66d500f3321ec2acb4c6801ca1e9 0.2s done\n",
      "#6 DONE 61.1s\n",
      "\n",
      "#7 [sagemaker-training 2/3] ADD ./src /opt/ml/code/\n",
      "#7 DONE 17.4s\n",
      "\n",
      "#8 [sagemaker-training 3/3] RUN pip install -r /opt/ml/code/requirements.txt\n",
      "#8 1.609 Collecting pandas==1.1.5\n",
      "#8 1.628   Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "#8 1.997 Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (2.8.1)\n",
      "#8 1.998 Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (2021.1)\n",
      "#8 2.000 Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (1.16.4)\n",
      "#8 2.004 Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r /opt/ml/code/requirements.txt (line 1)) (1.15.0)\n",
      "#8 2.668 Installing collected packages: pandas\n",
      "#8 2.668   Attempting uninstall: pandas\n",
      "#8 2.669     Found existing installation: pandas 0.25.0\n",
      "#8 2.978     Uninstalling pandas-0.25.0:\n",
      "#8 3.422       Successfully uninstalled pandas-0.25.0\n",
      "#8 6.858 Successfully installed pandas-1.1.5\n",
      "#8 DONE 7.7s\n",
      "\n",
      "#9 [sagemaker-training] exporting to image\n",
      "#9 exporting layers\n",
      "#9 exporting layers 0.5s done\n",
      "#9 writing image sha256:5c7a0b20d476147fed0d5253a94ceab4cd66921c7cd290efaa695f48409ac3e1\n",
      "#9 writing image sha256:5c7a0b20d476147fed0d5253a94ceab4cd66921c7cd290efaa695f48409ac3e1 done\n",
      "#9 naming to docker.io/library/my-custom-sagemaker-image done\n",
      "#9 DONE 0.6s\n",
      "DOCKER BUILD TERMINATED AT Thu Nov 23 08:17:55 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# See README.md for explanation\n",
    "# Hint: the ECR image we'll login for is the same we use as base image in the Dockerfile\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py3\n",
    "\n",
    "docker-compose build\n",
    "\n",
    "echo \"DOCKER BUILD TERMINATED AT $(date)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7550a",
   "metadata": {},
   "source": [
    "Using SageMaker Python SDK we can test our Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c57ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: my-custom-sagemaker-image-2023-11-23-08-22-58-947\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ESTIMATOR FIT STARTED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-zj958:\n",
      "    command: train\n",
      "    container_name: iovftmkohu-algo-1-zj958\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: my-custom-sagemaker-image\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-zj958\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmp956mc9q_/algo-1-zj958/input:/opt/ml/input\n",
      "    - /tmp/tmp956mc9q_/algo-1-zj958/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmp956mc9q_/algo-1-zj958/output:/opt/ml/output\n",
      "    - /tmp/tmp956mc9q_/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/2023-24-UFS14-ML/data/input:/opt/ml/input/data/training\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmp956mc9q_/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Network sagemaker-local  Creating\n",
      " Network sagemaker-local  Created\n",
      " Container iovftmkohu-algo-1-zj958  Creating\n",
      " Container iovftmkohu-algo-1-zj958  Created\n",
      "Attaching to iovftmkohu-algo-1-zj958\n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:01,177 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:01,192 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:01,206 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:01,210 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:01,211 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "iovftmkohu-algo-1-zj958  | /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "iovftmkohu-algo-1-zj958  | Requirement already satisfied: pandas==1.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.1.5)\n",
      "iovftmkohu-algo-1-zj958  | Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.16.4)\n",
      "iovftmkohu-algo-1-zj958  | Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\n",
      "iovftmkohu-algo-1-zj958  | Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\n",
      "iovftmkohu-algo-1-zj958  | Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:02,467 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:02,482 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:02,497 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:02,509 sagemaker-training-toolkit INFO     Invoking user script\n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | Training Env:\n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | {\n",
      "iovftmkohu-algo-1-zj958  |     \"additional_framework_parameters\": {},\n",
      "iovftmkohu-algo-1-zj958  |     \"channel_input_dirs\": {\n",
      "iovftmkohu-algo-1-zj958  |         \"training\": \"/opt/ml/input/data/training\"\n",
      "iovftmkohu-algo-1-zj958  |     },\n",
      "iovftmkohu-algo-1-zj958  |     \"current_host\": \"algo-1-zj958\",\n",
      "iovftmkohu-algo-1-zj958  |     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "iovftmkohu-algo-1-zj958  |     \"hosts\": [\n",
      "iovftmkohu-algo-1-zj958  |         \"algo-1-zj958\"\n",
      "iovftmkohu-algo-1-zj958  |     ],\n",
      "iovftmkohu-algo-1-zj958  |     \"hyperparameters\": {\n",
      "iovftmkohu-algo-1-zj958  |         \"epochs\": 1\n",
      "iovftmkohu-algo-1-zj958  |     },\n",
      "iovftmkohu-algo-1-zj958  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "iovftmkohu-algo-1-zj958  |     \"input_data_config\": {\n",
      "iovftmkohu-algo-1-zj958  |         \"training\": {\n",
      "iovftmkohu-algo-1-zj958  |             \"TrainingInputMode\": \"File\"\n",
      "iovftmkohu-algo-1-zj958  |         }\n",
      "iovftmkohu-algo-1-zj958  |     },\n",
      "iovftmkohu-algo-1-zj958  |     \"input_dir\": \"/opt/ml/input\",\n",
      "iovftmkohu-algo-1-zj958  |     \"is_master\": true,\n",
      "iovftmkohu-algo-1-zj958  |     \"job_name\": \"my-custom-sagemaker-image-2023-11-23-08-22-58-947\",\n",
      "iovftmkohu-algo-1-zj958  |     \"log_level\": 20,\n",
      "iovftmkohu-algo-1-zj958  |     \"master_hostname\": \"algo-1-zj958\",\n",
      "iovftmkohu-algo-1-zj958  |     \"model_dir\": \"/opt/ml/model\",\n",
      "iovftmkohu-algo-1-zj958  |     \"module_dir\": \"/opt/ml/code\",\n",
      "iovftmkohu-algo-1-zj958  |     \"module_name\": \"my-custom-training-script\",\n",
      "iovftmkohu-algo-1-zj958  |     \"network_interface_name\": \"eth0\",\n",
      "iovftmkohu-algo-1-zj958  |     \"num_cpus\": 4,\n",
      "iovftmkohu-algo-1-zj958  |     \"num_gpus\": 0,\n",
      "iovftmkohu-algo-1-zj958  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "iovftmkohu-algo-1-zj958  |     \"output_dir\": \"/opt/ml/output\",\n",
      "iovftmkohu-algo-1-zj958  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "iovftmkohu-algo-1-zj958  |     \"resource_config\": {\n",
      "iovftmkohu-algo-1-zj958  |         \"current_host\": \"algo-1-zj958\",\n",
      "iovftmkohu-algo-1-zj958  |         \"hosts\": [\n",
      "iovftmkohu-algo-1-zj958  |             \"algo-1-zj958\"\n",
      "iovftmkohu-algo-1-zj958  |         ]\n",
      "iovftmkohu-algo-1-zj958  |     },\n",
      "iovftmkohu-algo-1-zj958  |     \"user_entry_point\": \"my-custom-training-script.py\"\n",
      "iovftmkohu-algo-1-zj958  | }\n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | Environment variables:\n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | SM_HOSTS=[\"algo-1-zj958\"]\n",
      "iovftmkohu-algo-1-zj958  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "iovftmkohu-algo-1-zj958  | SM_HPS={\"epochs\":1}\n",
      "iovftmkohu-algo-1-zj958  | SM_USER_ENTRY_POINT=my-custom-training-script.py\n",
      "iovftmkohu-algo-1-zj958  | SM_FRAMEWORK_PARAMS={}\n",
      "iovftmkohu-algo-1-zj958  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-zj958\",\"hosts\":[\"algo-1-zj958\"]}\n",
      "iovftmkohu-algo-1-zj958  | SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "iovftmkohu-algo-1-zj958  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "iovftmkohu-algo-1-zj958  | SM_CHANNELS=[\"training\"]\n",
      "iovftmkohu-algo-1-zj958  | SM_CURRENT_HOST=algo-1-zj958\n",
      "iovftmkohu-algo-1-zj958  | SM_MODULE_NAME=my-custom-training-script\n",
      "iovftmkohu-algo-1-zj958  | SM_LOG_LEVEL=20\n",
      "iovftmkohu-algo-1-zj958  | SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "iovftmkohu-algo-1-zj958  | SM_INPUT_DIR=/opt/ml/input\n",
      "iovftmkohu-algo-1-zj958  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "iovftmkohu-algo-1-zj958  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "iovftmkohu-algo-1-zj958  | SM_NUM_CPUS=4\n",
      "iovftmkohu-algo-1-zj958  | SM_NUM_GPUS=0\n",
      "iovftmkohu-algo-1-zj958  | SM_MODEL_DIR=/opt/ml/model\n",
      "iovftmkohu-algo-1-zj958  | SM_MODULE_DIR=/opt/ml/code\n",
      "iovftmkohu-algo-1-zj958  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-zj958\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-zj958\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"my-custom-sagemaker-image-2023-11-23-08-22-58-947\",\"log_level\":20,\"master_hostname\":\"algo-1-zj958\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"my-custom-training-script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-zj958\",\"hosts\":[\"algo-1-zj958\"]},\"user_entry_point\":\"my-custom-training-script.py\"}\n",
      "iovftmkohu-algo-1-zj958  | SM_USER_ARGS=[\"--epochs\",\"1\"]\n",
      "iovftmkohu-algo-1-zj958  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "iovftmkohu-algo-1-zj958  | SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "iovftmkohu-algo-1-zj958  | SM_HP_EPOCHS=1\n",
      "iovftmkohu-algo-1-zj958  | PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | Invoking script with the following command:\n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | /opt/conda/bin/python3.6 my-custom-training-script.py --epochs 1\n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | \n",
      "iovftmkohu-algo-1-zj958  | 2023-11-23 08:23:02,560 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmp956mc9q_/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmp956mc9q_/algo-1-zj958/output/data/my-data.txt -> /tmp/tmp956mc9q_/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmp956mc9q_/algo-1-zj958/output/success -> /tmp/tmp956mc9q_/artifacts/output\n",
      "INFO:root:copying /tmp/tmp956mc9q_/model/my-model.txt -> /tmp/tmp956mc9q_/artifacts/model\n",
      "INFO:root:copying /tmp/tmp956mc9q_/compressed_artifacts/model.tar.gz -> /home/ec2-user/SageMaker/2023-24-UFS14-ML/data/output\n",
      "INFO:root:copying /tmp/tmp956mc9q_/compressed_artifacts/output.tar.gz -> /home/ec2-user/SageMaker/2023-24-UFS14-ML/data/output\n",
      "WARNING:sagemaker.local.image:Failed to delete: /tmp/tmp956mc9q_/algo-1-zj958 Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iovftmkohu-algo-1-zj958 exited with code 0\n",
      "Aborting on container exit...\n",
      " Container iovftmkohu-algo-1-zj958  Stopping\n",
      " Container iovftmkohu-algo-1-zj958  Stopped\n",
      "===== Job Complete =====\n",
      "##### ESTIMATOR FIT COMPLETED\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import os\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "hyperparameters={'epochs': 1}\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='my-custom-sagemaker-image',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path='file://{}/data/output'.format(os.getcwd())\n",
    ")\n",
    "\n",
    "print('##### ESTIMATOR FIT STARTED')\n",
    "estimator.fit('file://{}/data/input'.format(os.getcwd()))\n",
    "print('##### ESTIMATOR FIT COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630118d",
   "metadata": {},
   "source": [
    "NB: if you encountered an error related to `network sagemaker-local was found but has incorrect label com.docker.compose.network set to \"\"` run the following command in the terminal and retry the above cell\n",
    "`docker network prune --force`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166fda7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-model.txt\n",
      "data/\n",
      "data/my-data.txt\n",
      "success\n",
      "Check the above files in the /home/ec2-user/SageMaker/2023-24-UFS14-ML/data/output directory!!!!\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Extracting local training archives to see the results\n",
    "\n",
    "tar -xvf $PWD/data/output/model.tar.gz -C $PWD/data/output\n",
    "tar -xvf $PWD/data/output/output.tar.gz -C $PWD/data/output\n",
    "\n",
    "echo \"Check the above files in the $PWD/data/output directory!!!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558f42e",
   "metadata": {},
   "source": [
    "As our image works as expected we can build it again with the right ECR image URI and push it to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f7b01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name: my-custom-sagemaker-image ######################\n",
      "account: 543199671267 ######################\n",
      "region: us-east-1 ######################\n",
      "fullname: 543199671267.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-image:latest ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  1.889MB\n",
      "Step 1/6 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py3\n",
      " ---> e77085e0f844\n",
      "Step 2/6 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 9367924cee4f\n",
      "Step 3/6 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 2514b5bae171\n",
      "Step 4/6 : ADD ./src /opt/ml/code/\n",
      " ---> Using cache\n",
      " ---> 9af60cec3157\n",
      "Step 5/6 : ENV SAGEMAKER_PROGRAM my-custom-training-script.py\n",
      " ---> Using cache\n",
      " ---> c99f570fbfaa\n",
      "Step 6/6 : RUN pip install -r /opt/ml/code/requirements.txt\n",
      " ---> Using cache\n",
      " ---> 291b50f3ef92\n",
      "Successfully built 291b50f3ef92\n",
      "Successfully tagged my-custom-sagemaker-image:latest\n",
      "The push refers to repository [543199671267.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-image]\n",
      "ba7ded278d75: Preparing\n",
      "d441fd28c744: Preparing\n",
      "6160e55345f6: Preparing\n",
      "b8897f99fee4: Preparing\n",
      "dc1b4f416d27: Preparing\n",
      "912a9194a89a: Preparing\n",
      "0bb6ba7c32f9: Preparing\n",
      "d6b6f976152c: Preparing\n",
      "bd9ea4625f76: Preparing\n",
      "31aed7f45c93: Preparing\n",
      "2dc64f428e8f: Preparing\n",
      "6225f83539e8: Preparing\n",
      "dbcf411e8bf0: Preparing\n",
      "5276d2b930fc: Preparing\n",
      "e6feec0db89a: Preparing\n",
      "697949baa658: Preparing\n",
      "935c56d8b3f9: Preparing\n",
      "2dc64f428e8f: Waiting\n",
      "6225f83539e8: Waiting\n",
      "dbcf411e8bf0: Waiting\n",
      "5276d2b930fc: Waiting\n",
      "912a9194a89a: Waiting\n",
      "e6feec0db89a: Waiting\n",
      "0bb6ba7c32f9: Waiting\n",
      "697949baa658: Waiting\n",
      "935c56d8b3f9: Waiting\n",
      "d6b6f976152c: Waiting\n",
      "31aed7f45c93: Waiting\n",
      "bd9ea4625f76: Waiting\n",
      "ba7ded278d75: Layer already exists\n",
      "dc1b4f416d27: Layer already exists\n",
      "6160e55345f6: Layer already exists\n",
      "b8897f99fee4: Layer already exists\n",
      "d441fd28c744: Layer already exists\n",
      "912a9194a89a: Layer already exists\n",
      "0bb6ba7c32f9: Layer already exists\n",
      "d6b6f976152c: Layer already exists\n",
      "31aed7f45c93: Layer already exists\n",
      "2dc64f428e8f: Layer already exists\n",
      "6225f83539e8: Layer already exists\n",
      "bd9ea4625f76: Layer already exists\n",
      "dbcf411e8bf0: Layer already exists\n",
      "5276d2b930fc: Layer already exists\n",
      "e6feec0db89a: Layer already exists\n",
      "697949baa658: Layer already exists\n",
      "935c56d8b3f9: Layer already exists\n",
      "latest: digest: sha256:9c451ac5dc5bc11db3efc841688c0a3999ddf5eb1aa6f74a2068786b4f6d9b09 size: 3876\n",
      "Docker push ended at Thu Nov 23 09:09:10 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an image name\n",
    "image_name=my-custom-sagemaker-image\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:latest\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Log into Docker\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${image_name} .\n",
    "docker tag ${image_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "echo \"Docker push ended at $(date)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e61d0ec",
   "metadata": {},
   "source": [
    "NB: if the last command \"docker push\" remain pending check README.md \"AWS ECR IAM policies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482fadcb",
   "metadata": {},
   "source": [
    "Before executing a training job on SageMaker we need to move our input data to AWS S3.\n",
    "Obv. we also need an S3 bucket first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e27a8",
   "metadata": {},
   "source": [
    "Create an S3 bucket using AWS CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a50801af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_S3_BUCKET_NAME=my-bucket-kuz\n"
     ]
    }
   ],
   "source": [
    "# Generate a random AWS S3 bucket name sharing the name between sh/bash and other Python cells.\n",
    "# NB: need to be executed only the first time you want to create the AWS S3 bucket\n",
    "bucket_name='my-bucket-kuz'\n",
    "%set_env AWS_S3_BUCKET_NAME=$bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c7819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Location\": \"/my-bucket-kuz\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# NB: need to be executed only the first time you want to create the AWS S3 bucket\n",
    "aws s3api create-bucket --bucket $AWS_S3_BUCKET_NAME --region $(aws configure get region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284b5bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12036/1500896753.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df_demo = pd.read_csv(url,',')\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 3)\n",
      "(7, 3)\n",
      "(7, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "\n",
    "url = 'file://{}/data/input/my-input-csv-file.csv'.format(os.getcwd())\n",
    "df_demo = pd.read_csv(url,',')\n",
    "\n",
    "prefix='demo'\n",
    "train_file='demo_train.csv'\n",
    "test_file='demo_test.csv'\n",
    "validate_file='demo_validate.csv'\n",
    "whole_file='demo.csv'\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "train, test_and_validate = train_test_split(df_demo, \n",
    "                                            test_size=0.2, \n",
    "                                            random_state=42, \n",
    "                                            stratify=df_demo['quality'])\n",
    "\n",
    "test, validate = train_test_split(test_and_validate, \n",
    "                                  test_size=0.5, \n",
    "                                  random_state=42, \n",
    "                                  stratify=test_and_validate['quality'])\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket_name).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket_name, prefix, train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket_name, prefix, validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ea70e",
   "metadata": {},
   "source": [
    "As we have pushed our Docker image to ECR and uploaded our input data to AWS S3 we can use it with a training job on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aad5656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### ecr_image is: 543199671267.dkr.ecr.us-east-1.amazonaws.com/my-custom-sagemaker-image:latest\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: custom-docker-image-for-training-2023-11-23-09-13-53-709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-23 09:13:53 Starting - Starting the training job......\n",
      "2023-11-23 09:14:27 Starting - Preparing the instances for training............\n",
      "2023-11-23 09:16:46 Downloading - Downloading input data......\n",
      "2023-11-23 09:17:32 Training - Downloading the training image...\n",
      "2023-11-23 09:17:57 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-11-23 09:18:31,262 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-11-23 09:18:31,286 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-11-23 09:18:31,289 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-11-23 09:18:31,290 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas==1.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.16.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-11-23 09:18:32,669 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"custom-docker-image-for-training-2023-11-23-09-13-53-709\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"my-custom-training-script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p2.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p2.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"my-custom-training-script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=my-custom-training-script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=my-custom-training-script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"custom-docker-image-for-training-2023-11-23-09-13-53-709\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"my-custom-training-script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"my-custom-training-script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 my-custom-training-script.py\u001b[0m\n",
      "\u001b[34m2023-11-23 09:18:32,721 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-11-23 09:18:53 Uploading - Uploading generated training model\n",
      "2023-11-23 09:18:53 Completed - Training job completed\n",
      "Training seconds: 127\n",
      "Billable seconds: 127\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "client=boto3.client('sts')\n",
    "account=client.get_caller_identity()['Account']\n",
    "\n",
    "my_session=boto3.session.Session()\n",
    "region=my_session.region_name\n",
    "\n",
    "image_name='my-custom-sagemaker-image'\n",
    "ecr_image='{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, image_name)\n",
    "print('###### ecr_image is: {}'.format(ecr_image))\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri=ecr_image,\n",
    "    role=get_execution_role(),\n",
    "    base_job_name='custom-docker-image-for-training',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p2.xlarge',\n",
    "    output_path='s3://{}'.format(bucket_name)\n",
    ")\n",
    "\n",
    "# start training\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8482a1",
   "metadata": {},
   "source": [
    "TODO: deploy our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f493af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: custom-docker-image-for-training-2023-11-23-09-29-22-577\n",
      "INFO:sagemaker:Creating endpoint-config with name custom-docker-image-for-training-2023-11-23-09-29-22-577\n",
      "INFO:sagemaker:Creating endpoint with name custom-docker-image-for-training-2023-11-23-09-29-22-577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint custom-docker-image-for-training-2023-11-23-09-29-22-577: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# deploy the trained model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m instance_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml.p2.xlarge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m predictor\u001b[38;5;241m=\u001b[39m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:1654\u001b[0m, in \u001b[0;36mEstimatorBase.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, use_compiled_model, wait, model_name, kms_key, data_capture_config, tags, serverless_inference_config, async_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m model\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m model_name\n\u001b[1;32m   1650\u001b[0m tags \u001b[38;5;241m=\u001b[39m update_inference_tags_with_jumpstart_training_tags(\n\u001b[1;32m   1651\u001b[0m     inference_tags\u001b[38;5;241m=\u001b[39mtags, training_tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m   1652\u001b[0m )\n\u001b[0;32m-> 1654\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_instance_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvolume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvolume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_data_download_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_data_download_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_recommendation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_recommendation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/model.py:1495\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1493\u001b[0m     explainer_config_dict \u001b[38;5;241m=\u001b[39m explainer_config\u001b[38;5;241m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_from_production_variants\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduction_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mproduction_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1507\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:4851\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict)\u001b[0m\n\u001b[1;32m   4848\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating endpoint-config with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m   4849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_options)\n\u001b[0;32m-> 4851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\n\u001b[1;32m   4853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:4196\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   4192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint(\n\u001b[1;32m   4193\u001b[0m     EndpointName\u001b[38;5;241m=\u001b[39mendpoint_name, EndpointConfigName\u001b[38;5;241m=\u001b[39mconfig_name, Tags\u001b[38;5;241m=\u001b[39mtags\n\u001b[1;32m   4194\u001b[0m )\n\u001b[1;32m   4195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4196\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint_name\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:4548\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   4542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   4543\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   4544\u001b[0m             message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   4545\u001b[0m             allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   4546\u001b[0m             actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   4547\u001b[0m         )\n\u001b[0;32m-> 4548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   4549\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   4550\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   4551\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   4552\u001b[0m     )\n\u001b[1;32m   4553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint custom-docker-image-for-training-2023-11-23-09-29-22-577: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "# deploy the trained model\n",
    "instance_type = \"ml.p2.xlarge\"\n",
    "predictor=estimator.deploy(1, instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c682377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
